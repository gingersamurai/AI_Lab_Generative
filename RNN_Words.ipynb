{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.data import Dataset, AUTOTUNE\n",
        "from tensorflow import keras\n",
        "from typing import Dict, Tuple\n",
        "import re\n",
        "import keras.layers as l\n",
        "from keras import models, callbacks, utils, losses"
      ],
      "metadata": {
        "id": "EvyxcS-gmU2R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "with open('harry_potter.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "def get_features_target(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    features = seq[:-1]\n",
        "    target = seq[1:]\n",
        "    return features, target\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "words = list(filter(None, [re.sub('[^а-яА-ЯёЁ0-9 ,-]', '', s).strip() for s in text.split('.')]))\n",
        "alphabet = np.array(sorted(set(' '.join(words).split(' '))))\n",
        "\n",
        "word_index = {char: i for i, char in enumerate(alphabet)}\n",
        "index_word = {i: char for i, char in enumerate(alphabet)}\n",
        "\n",
        "sequences = Dataset.from_tensor_slices(np.array([word_index[word] for word in ' '.join(words).split()])).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset = sequences.map(get_features_target)\n",
        "\n",
        "data = dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "data = data.prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "h808pCammmwI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    l.Embedding(len(alphabet), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
        "    l.SimpleRNN(128, return_sequences=True, stateful=True),\n",
        "    l.Dense(len(alphabet) / 2, activation='relu'),\n",
        "    l.Dense(len(alphabet))\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.fit(data, epochs=50, verbose=1, steps_per_epoch= len(sequences) // BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH7Bjz_gEwU-",
        "outputId": "40b99c6d-878f-484b-e564-09a3f0c216a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 1s 60ms/step - loss: 8.1396 - accuracy: 0.0141\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 7.6717 - accuracy: 0.0239\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 7.3871 - accuracy: 0.0215\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 7.3807 - accuracy: 0.0239\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 7.3629 - accuracy: 0.0239\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 7.3576 - accuracy: 0.0239\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 7.3426 - accuracy: 0.0239\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 7.3357 - accuracy: 0.0239\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 7.3212 - accuracy: 0.0239\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 7.3042 - accuracy: 0.0239\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 7.2693 - accuracy: 0.0239\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 7.2017 - accuracy: 0.0245\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 7.0886 - accuracy: 0.0262\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 6.9357 - accuracy: 0.0309\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 6.6885 - accuracy: 0.0336\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 6.3296 - accuracy: 0.0381\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 5.9773 - accuracy: 0.0437\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 5.3683 - accuracy: 0.0566\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 4.7332 - accuracy: 0.1129\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 3.8435 - accuracy: 0.3967\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 2.8455 - accuracy: 0.5867\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 2.0854 - accuracy: 0.6272\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.6444 - accuracy: 0.6749\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.3699 - accuracy: 0.7179\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 1.1753 - accuracy: 0.7525\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.0256 - accuracy: 0.7796\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.9093 - accuracy: 0.8091\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.8068 - accuracy: 0.8337\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.7241 - accuracy: 0.8547\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.6501 - accuracy: 0.8701\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.5831 - accuracy: 0.8871\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.5225 - accuracy: 0.9032\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.4674 - accuracy: 0.9183\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.4175 - accuracy: 0.9303\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.3717 - accuracy: 0.9425\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.3301 - accuracy: 0.9531\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.2924 - accuracy: 0.9600\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.2585 - accuracy: 0.9694\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.2282 - accuracy: 0.9751\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.2013 - accuracy: 0.9803\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.1774 - accuracy: 0.9844\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.1565 - accuracy: 0.9879\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.1382 - accuracy: 0.9904\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.1222 - accuracy: 0.9934\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.1083 - accuracy: 0.9946\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.0962 - accuracy: 0.9958\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0857 - accuracy: 0.9966\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0767 - accuracy: 0.9971\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0688 - accuracy: 0.9975\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0620 - accuracy: 0.9982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d7d11ff85e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next(sample: str, model: keras.Sequential, tokenizer: Dict[str, int], vocabulary: Dict[int, str], n_next: int, temperature: float, batch_size: int, word: bool = False) -> str:\n",
        "    if word:\n",
        "        sample_vector = [tokenizer[word] for word in sample.split()]\n",
        "    else:\n",
        "        sample_vector = [tokenizer[char] for char in sample]\n",
        "    predicted = sample_vector\n",
        "    sample_tensor = tf.expand_dims(sample_vector, 0)\n",
        "    sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
        "    for i in range(n_next):\n",
        "        pred = model(sample_tensor)\n",
        "        pred = pred[0].numpy() / temperature\n",
        "        pred = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
        "        predicted.append(pred)\n",
        "        sample_tensor = predicted[-99:]\n",
        "        sample_tensor = tf.expand_dims([pred], 0)\n",
        "        sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
        "    pred_seq = [vocabulary[i] for i in predicted]\n",
        "    generated = ' '.join(pred_seq) if word else ''.join(pred_seq)\n",
        "    return generated"
      ],
      "metadata": {
        "id": "qPRCuF4jtcrQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next(\n",
        "    sample='Гарри',\n",
        "    model=model,\n",
        "    tokenizer=word_index,\n",
        "    vocabulary=index_word,\n",
        "    n_next=20,\n",
        "    temperature=0.6,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    word=True\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mif8PcHiGzv3",
        "outputId": "f1fdc031-36d3-48cd-df68-a7130a84218f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Гарри лунном свете блестит полоска серебрападают тёмные одежды кровь льётся литрами, и слышен крик Все стены до последнего дюйма заняты книжными\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next(\n",
        "    sample='Магия',\n",
        "    model=model,\n",
        "    tokenizer=word_index,\n",
        "    vocabulary=index_word,\n",
        "    n_next=20,\n",
        "    temperature=0.6,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    word=True\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4BA_0irxMui",
        "outputId": "1ed4d892-cf7b-46dc-9872-6443925d97b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Магия шкафами Гарри каждом мне три поднимать книги с одной профессор, с читаю Она мама Каким образом хранилище взгляд ещё их\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next(\n",
        "    sample='МакГонагалл',\n",
        "    model=model,\n",
        "    tokenizer=word_index,\n",
        "    vocabulary=index_word,\n",
        "    n_next=20,\n",
        "    temperature=0.6,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    word=True\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbrkLYzxRPV",
        "outputId": "907e7dee-b47c-4240-f7bc-16d9dac8fc98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "МакГонагалл себе часть Ты Его были все Гарри, но же не Что к ответила за было бы стояли нам ничего все\n"
          ]
        }
      ]
    }
  ]
}